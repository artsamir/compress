# Robots.txt for Cutcompress - SEO Optimization

# Allow all bots
User-agent: *
Allow: /

# Specific rules for Google
User-agent: Googlebot
Allow: /
Crawl-delay: 0

# Specific rules for Bing
User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Disallow private/admin areas
Disallow: /admin/
Disallow: /api/
Disallow: /private/
Disallow: /*.json$
Disallow: /*.xml$

# Disallow authentication pages (duplicate content, not for indexing)
Disallow: /login
Disallow: /signup
Disallow: /thankyou

# Disallow legal pages (can index via meta tag noindex instead)
Disallow: /privacy-policy
Disallow: /terms
Disallow: /refund-policy

# Sitemap location
Sitemap: https://www.cutcompress.com/sitemap.xml

# Cache settings
Request-rate: 10/1m
